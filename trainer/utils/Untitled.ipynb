{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import polarTransform\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "DEFAULT_BUCKET_DIR = 'gs://duke-research-us/mimicknet/data/duke-ultrasound-v1'\n",
    "\n",
    "class MimickDataset():\n",
    "    def __init__(self, clipping=(-80,0), divisible=16, sc=False, shape=None, image_dir=None, bucket_dir=DEFAULT_BUCKET_DIR):\n",
    "        self.image_dir = bucket_dir if image_dir is None else image_dir\n",
    "        self.clipping = clipping\n",
    "        self.sc = sc\n",
    "        self.divisible = divisible\n",
    "        self.shape = shape\n",
    "        \n",
    "    def read_mat_op(self, filename):           \n",
    "        filepath = tf.io.gfile.GFile(filename.numpy(), 'rb')\n",
    "        matfile = sio.loadmat(filepath) if not self.sc else loadmat(filepath)\n",
    "\n",
    "        # normalize dtce to [0, 1]\n",
    "        dtce = matfile['dtce']\n",
    "        dtce = (dtce - dtce.min())/(dtce.max() - dtce.min())\n",
    "\n",
    "        # signal detect, clip, and normalize\n",
    "        iq = np.abs(matfile['iq'])\n",
    "        if self.clipping is not None:        \n",
    "            iq = 20*np.log10(iq/iq.max())\n",
    "            iq = np.clip(iq, self.clipping[0], self.clipping[1])\n",
    "        elif self.log_compress: \n",
    "            iq = np.log10(iq)\n",
    "        iq = (iq-iq.min())/(iq.max() - iq.min())\n",
    "\n",
    "        # scan convert TODO (this process is heavy so it should be preprocessed)\n",
    "        if self.sc:\n",
    "            iq = scan_convert(iq, matfile['acq_params'])\n",
    "            dtce = scan_convert(dtce, matfile['acq_params'])\n",
    "\n",
    "        seed = np.random.randint(0, 2147483647)\n",
    "        iq, _ = make_shape(iq, shape=self.shape, divisible=self.divisible, seed=seed)\n",
    "        dtce, _ = make_shape(dtce, shape=self.shape, divisible=self.divisible, seed=seed)  \n",
    "        return iq.astype('float32'), dtce.astype('float32')\n",
    "    \n",
    "    def reshape(iq, dtce, shape):\n",
    "        output_shape = tf.concat([shape, [1]], axis=0)\n",
    "        iq = tf.reshape(iq, output_shape)\n",
    "        dtce = tf.reshape(dtce, output_shape)\n",
    "        return iq, dtce\n",
    "\n",
    "    def get_dataset(self, csv):\n",
    "        filepath = tf.io.gfile.GFile(csv, 'rb')\n",
    "        filelist = pd.read_csv(filepath)\n",
    "        filelist['filename'] = filelist['filename'].apply(lambda x: '{}/{}'.format(self.image_dir, x))\n",
    "        filelist = list(filelist['filename'])\n",
    "        count = len(filelist)\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices(filelist)\n",
    "        dataset = dataset.shuffle(count).repeat()\n",
    "        dataset = dataset.map(lambda x: tf.py_function(self.read_mat_op, [x], [tf.float32, tf.float32]), \n",
    "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        return dataset, count\n",
    "\n",
    "    def get_paired_ultrasound_dataset(self, csv='gs://duke-research-us/mimicknet/data/training-v1.csv', batch_size=16):\n",
    "        dataset, count = self.get_dataset(csv)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(batch_size)\n",
    "        return dataset, count\n",
    "\n",
    "    def get_unpaired_ultrasound_dataset(self, domain, csv=None, batch_size=16):\n",
    "        if domain == 'iq':\n",
    "            csv = 'gs://duke-research-us/mimicknet/data/training_a.csv' if csv is None else csv\n",
    "            dataset, count = self.get_dataset(csv)\n",
    "            dataset = dataset.map(lambda iq, dtce: iq)\n",
    "        \n",
    "        elif domain == 'dtce':\n",
    "            csv = 'gs://duke-research-us/mimicknet/data/training_b.csv' if csv is None else csv\n",
    "            dataset, count = self.get_dataset(csv)\n",
    "            dataset = dataset.map(lambda iq, dtce: dtce)\n",
    "        else:\n",
    "            raise Exception('domain must be \"iq\" or \"dtce\", given {}'.format(domain))\n",
    "        \n",
    "        dataset = dataset.batch(batch_size).prefetch(batch_size)\n",
    "        return dataset, count\n",
    "    \n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct sio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], sio.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, sio.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, sio.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = sio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "\n",
    "def make_shape(image, shape=None, divisible=16, seed=0):\n",
    "    \"\"\"Will reflection pad or crop to make an image divisible by a number.\n",
    "    \n",
    "    If shape is smaller than the original image, it will be cropped randomly\n",
    "    If shape is larger than the original image, it will be refection padded\n",
    "    If shape is None, the image's original shape will be minimally padded to be divisible by a number.\n",
    "    \n",
    "    Arguments:\n",
    "        image {np.array} -- np.array that is (height, width, channels)\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        shape {tuple} -- shape of image desired (default: {None})\n",
    "        seed {number} -- random seed for random cropping (default: {0})\n",
    "        divisible {number} -- number to be divisible by (default: {16})\n",
    "    \n",
    "    Returns:\n",
    "        np.array, (int, int) -- divisible image no matter the shape, and a tuple of the original size.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed=seed)\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "\n",
    "    shape = shape if shape is not None else image.shape\n",
    "    height = shape[0] if shape[0] % divisible == 0 else (divisible - shape[0] % divisible) + shape[0]\n",
    "    width = shape[1] if shape[1] % divisible == 0 else (divisible - shape[1] % divisible) + shape[1]\n",
    "\n",
    "    # Pad data to batch height and width with reflections, and randomly crop\n",
    "    if image_height < height:\n",
    "        remainder = height - image_height\n",
    "        if remainder % 2 == 0:\n",
    "            image = np.pad(image, ((int(remainder/2), int(remainder/2)), (0,0)), 'reflect')\n",
    "        else:\n",
    "            remainder = remainder - 1\n",
    "            image = np.pad(image, ((int(remainder/2) + 1, int(remainder/2)), (0,0)), 'reflect')\n",
    "    elif image_height > height:\n",
    "        start = np.random.randint(0, image_height - height)\n",
    "        image = image[start:start+height, :]\n",
    "\n",
    "    if image_width < width:\n",
    "        remainder = width - image_width\n",
    "        if remainder % 2 == 0:\n",
    "            image = np.pad(image, ((0,0), (int(remainder/2), int(remainder/2))), 'reflect')\n",
    "        else:\n",
    "            remainder = remainder - 1\n",
    "            image = np.pad(image, ((0,0), (int(remainder/2) + 1, int(remainder/2))), 'reflect')\n",
    "    elif image_width > width:\n",
    "        start = np.random.randint(0, image_width - width)\n",
    "        image = image[:, start:start+width]\n",
    "    image = image[:,:, None]\n",
    "    \n",
    "    return image, (image_height, image_width)\n",
    "\n",
    "def scan_convert(image, acq_params):\n",
    "    # Takes an image (r, theta), and acq_params dictionary\n",
    "    r = acq_params['r']\n",
    "    apex = acq_params['apex'] if 'apex' in acq_params else acq_params['apex_coordinates'][2]\n",
    "    theta = acq_params['theta']\n",
    "    initial_radius = abs((r[0] - apex)/(r[1]-r[0]))\n",
    "    image, _ = polarTransform.convertToCartesianImage(\n",
    "        np.transpose(image),\n",
    "        initialRadius=initial_radius,\n",
    "        finalRadius=initial_radius+image.shape[0],\n",
    "        initialAngle=theta[0],\n",
    "        finalAngle=theta[-1],\n",
    "        hasColor=False,\n",
    "        order=3)\n",
    "    return np.transpose(image[:, int(initial_radius):])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimick_dataset = MimickDataset()\n",
    "train_dataset, train_count = mimick_dataset.get_paired_ultrasound_dataset(\n",
    "    csv='gs://duke-research-us/mimicknet/data/training-v1.csv', \n",
    "    batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_dataset: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 896, 64, 1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.io.gfile.GFile('gs://duke-research-us/mimicknet/data/training-v1.csv', 'rb')\n",
    "filelist = list(pd.read_csv(filepath)['filename'])\n",
    "count = len(filelist)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.io.gfile.GFile('gs://duke-research-us/mimicknet/data/training-v1.csv', 'rb')\n",
    "filelist = pd.read_csv(filepath)\n",
    "filelist['filename'] = filelist['filename'].apply(lambda x: '{}/{}'.format('gs://duke-research-us/mimicknet/data/duke-ultrasound-v1', x))\n",
    "filelist = list(filelist['filename'])\n",
    "count = len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mat(filepath):\n",
    "    filepath = tf.io.gfile.GFile(filepath, 'rb')\n",
    "    matfile = sio.loadmat(filepath)\n",
    "    \n",
    "    return matfile['iq'].astype('float32'), abs(matfile['dtce']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (<unknown>, <unknown>, <unknown>), types: (tf.float32, tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(lambda x: tf.py_function(parse_mat, [x], [tf.float32, tf.float32, tf.int64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(filename):\n",
    "    filepath = tf.io.gfile.GFile(filename, 'rb')\n",
    "    print(filepath)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.platform.gfile.GFile object at 0x7fd1143a7278>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __inference_Dataset_map_<class 'functools.partial'>_1257}} UnboundLocalError: local variable 'err' referenced before assignment\nTraceback (most recent call last):\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/script_ops.py\", line 219, in __call__\n    return func(device, token, args)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/script_ops.py\", line 113, in __call__\n    ret = self._func(*args)\n\n  File \"/tmp/tmpijvelrv_.py\", line 18, in _read_mat\n    matfile = ag__.if_stmt(ag__.not_(scan_convert), lambda : ag__.converted_call(sio.loadmat, ag__.STD, (filepath,), None), lambda : ag__.converted_call(loadmat, ag__.STD, (filepath,), None), lambda : (), lambda _: None)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 623, in if_stmt\n    return _py_if_stmt(cond, body, orelse)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 710, in _py_if_stmt\n    return body() if cond else orelse()\n\n  File \"/tmp/tmpijvelrv_.py\", line 18, in <lambda>\n    matfile = ag__.if_stmt(ag__.not_(scan_convert), lambda : ag__.converted_call(sio.loadmat, ag__.STD, (filepath,), None), lambda : ag__.converted_call(loadmat, ag__.STD, (filepath,), None), lambda : (), lambda _: None)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 512, in converted_call\n    result = converted_f(*effective_args)\n\n  File \"/tmp/tmpcfmcglgr.py\", line 171, in tf__loadmat\n    data = ag__.converted_call(sio.loadmat, ag__.STD, (filename,), {'struct_as_record': False, 'squeeze_me': True})\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 510, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n\n  File \"/tmp/tmpswdwga7k.py\", line 78, in tf__loadmat\n    matfile_dict = ag__.converted_call(MR.get_variables, ag__.STD, (variable_names,), None)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 512, in converted_call\n    result = converted_f(*effective_args)\n\n  File \"/tmp/tmpg1naeyfz.py\", line 193, in tf__get_variables\n    break_, err = ag__.while_stmt(loop_test, loop_body, get_state_9, set_state_9, (break_, err))\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 473, in while_stmt\n    init_vars = body(*init_vars)\n\n  File \"/tmp/tmpg1naeyfz.py\", line 188, in loop_body\n    break_, err = ag__.if_stmt(cond_8, if_true_8, if_false_8, get_state_8, set_state_8)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 623, in if_stmt\n    return _py_if_stmt(cond, body, orelse)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 710, in _py_if_stmt\n    return body() if cond else orelse()\n\n  File \"/tmp/tmpg1naeyfz.py\", line 183, in if_true_8\n    return break__2, err\n\nUnboundLocalError: local variable 'err' referenced before assignment\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a086ddb753bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2308\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __inference_Dataset_map_<class 'functools.partial'>_1257}} UnboundLocalError: local variable 'err' referenced before assignment\nTraceback (most recent call last):\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/script_ops.py\", line 219, in __call__\n    return func(device, token, args)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/script_ops.py\", line 113, in __call__\n    ret = self._func(*args)\n\n  File \"/tmp/tmpijvelrv_.py\", line 18, in _read_mat\n    matfile = ag__.if_stmt(ag__.not_(scan_convert), lambda : ag__.converted_call(sio.loadmat, ag__.STD, (filepath,), None), lambda : ag__.converted_call(loadmat, ag__.STD, (filepath,), None), lambda : (), lambda _: None)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 623, in if_stmt\n    return _py_if_stmt(cond, body, orelse)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 710, in _py_if_stmt\n    return body() if cond else orelse()\n\n  File \"/tmp/tmpijvelrv_.py\", line 18, in <lambda>\n    matfile = ag__.if_stmt(ag__.not_(scan_convert), lambda : ag__.converted_call(sio.loadmat, ag__.STD, (filepath,), None), lambda : ag__.converted_call(loadmat, ag__.STD, (filepath,), None), lambda : (), lambda _: None)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 512, in converted_call\n    result = converted_f(*effective_args)\n\n  File \"/tmp/tmpcfmcglgr.py\", line 171, in tf__loadmat\n    data = ag__.converted_call(sio.loadmat, ag__.STD, (filename,), {'struct_as_record': False, 'squeeze_me': True})\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 510, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n\n  File \"/tmp/tmpswdwga7k.py\", line 78, in tf__loadmat\n    matfile_dict = ag__.converted_call(MR.get_variables, ag__.STD, (variable_names,), None)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 512, in converted_call\n    result = converted_f(*effective_args)\n\n  File \"/tmp/tmpg1naeyfz.py\", line 193, in tf__get_variables\n    break_, err = ag__.while_stmt(loop_test, loop_body, get_state_9, set_state_9, (break_, err))\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 473, in while_stmt\n    init_vars = body(*init_vars)\n\n  File \"/tmp/tmpg1naeyfz.py\", line 188, in loop_body\n    break_, err = ag__.if_stmt(cond_8, if_true_8, if_false_8, get_state_8, set_state_8)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 623, in if_stmt\n    return _py_if_stmt(cond, body, orelse)\n\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 710, in _py_if_stmt\n    return body() if cond else orelse()\n\n  File \"/tmp/tmpg1naeyfz.py\", line 183, in if_true_8\n    return break__2, err\n\nUnboundLocalError: local variable 'err' referenced before assignment\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]"
     ]
    }
   ],
   "source": [
    "for x in train_dataset: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
